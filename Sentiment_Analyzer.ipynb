{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOvE/h6M4cUxW2WiL9yFlC3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#GUI - Sentiment Analyzer\n","\n","Vicente De Leon"],"metadata":{"id":"z22D7jwg8XyV"}},{"cell_type":"markdown","source":["##Important:\n","\n","In order to build this web application 2 datasets:\n","\n","- Spotify.csv\n","\n","- movie_reviews.csv (this one came from on of our coding practices)\n","\n","Both csv files can be used in the Text Cleaner selection.\n","\n","\n","\n","**Sportify**:\n","- after being cleaned, this dataset can be used for the TextBlob Analysis in order to get 3 sentiments -> positive, neutral, negative.\n","\n","- You can even use the raw uncleaned csv for the VADER analysis, since this unsupervised model doesn't need clean data in order to perform. It even takes on emojies to calculate sentiment.\n","\n","\n","\n","**Movie Reviews:**\n","- After being cleaned, this dataset can be used for both Logistic Regression and Support Vector Machine, since the original dataset came with a sentiment column. It is important to note that unlike TextBlob and VADER, our Unsupervised Models (Logistic and SVM) only calculate 2 sentiments -> positive and negative.\n","\n","\n","\n"],"metadata":{"id":"grtobHlR8xA5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wePf4vGwM0lw"},"outputs":[],"source":["!pip install streamlit"]},{"cell_type":"code","source":["%%writefile main_app.py\n","\n","import streamlit as st\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import sys\n","import matplotlib.pyplot as plt\n","import re\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('vader_lexicon')\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","np.set_printoptions(precision=2, linewidth=80)\n","\n","from sklearn import metrics\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import SGDClassifier\n","\n","\n","import warnings \n","warnings.filterwarnings('ignore')\n","\n","######################### functions clean text\n","\n","stop_words = nltk.corpus.stopwords.words('english')\n","\n","def normalize_document(doc):\n","    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n","    doc = doc.lower()\n","    doc = doc.strip()\n","    tokens = nltk.word_tokenize(doc)\n","    filtered_tokens = [token for token in tokens if token not in stop_words] \n","    doc = ' '.join(filtered_tokens)\n","    return doc\n","  \n","normalize_corpus = np.vectorize(normalize_document)\n","\n","\n","########################## df to csv and download generator custome functions:\n","\n","def convert_df(df):\n","             return df.to_csv().encode('utf-8')\n","\n","\n","def generate_download_button(csv_data, filename, file_label):\n","    st.download_button(label=f\"Download {file_label} as CSV\",\n","                           data=csv_data,\n","                           file_name=f\"{filename}.csv\")\n","\n","\n","######################### custome functions TextBlob\n","\n","from textblob import TextBlob\n","\n","def polarity(txt):\n","    try:\n","        return TextBlob(txt).sentiment.polarity\n","    except:\n","        return None\n","\n","def subjectivity(txt):\n","  try:\n","      return TextBlob(txt).sentiment.subjectivity\n","  except:\n","        return None\n","\n","def analyze(x):\n","        if x < 0:\n","            return 'negative'\n","        elif x == 0:\n","            return 'neutral'\n","        else:\n","            return 'positive'\n","\n","\n","###################################################################### Functions for sentiment VADER analysis:\n","\n","analyzer = SentimentIntensityAnalyzer()\n","\n","def vader_sentiment(txt):\n","  try:\n","      return analyzer.polarity_scores(txt)['compound']\n","  except:\n","      return None\n","\n","\n","def vader_analysis(sentiment, neg_threshold=-0.05, pos_threshold=0.05):\n","    if sentiment < neg_threshold:\n","        label = 'negative'\n","    elif sentiment > pos_threshold:\n","        label = 'positive'\n","    else:\n","        label = 'neutral'\n","    return label\n","\n","\n","#################################################### functions Supervised Learning\n","\n","def get_metrics(true_labels, predicted_labels):\n","  st.write('Accuracy:', np.round(metrics.accuracy_score(true_labels, predicted_labels), 4))\n","  st.write('Precision:',np.round(metrics.precision_score(true_labels, predicted_labels, average = 'weighted'), 4))\n","  st.write('Recall:',np.round(metrics.recall_score(true_labels, predicted_labels, average = 'weighted'), 4))\n","  st.write('F1 Score:',np.round(metrics.f1_score(true_labels, predicted_labels, average = 'weighted'), 4))\n","\n","def train_predict_model(classifier, \n","                        train_features, train_labels, \n","                        test_features, test_labels):   \n","    classifier.fit(train_features, train_labels)\n","    predictions = classifier.predict(test_features) \n","    return predictions   \n","\n","\n","# custom function\n","\n","def classification_report(true_labels, predicted_labels, classes=[1,0], output_dict=True):\n","  report = metrics.classification_report(y_true=true_labels, y_pred = predicted_labels, labels = classes, output_dict=True)\n","  return(report)\n","\n","def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n","    \n","    total_classes = len(classes)\n","    level_labels = [total_classes*[0], list(range(total_classes))]\n","\n","    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n","                                  labels=classes)\n","    cm_frame = pd.DataFrame(data=cm, \n","                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n","                                                  codes=level_labels), \n","                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n","                                                codes=level_labels)) \n","    st.write(cm_frame) \n","    \n","\n","def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n","    st.write('Model Performance metrics:')\n","    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n","    st.write('\\n')\n","    st.write('Prediction Confusion Matrix:')\n","    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n","                             classes=classes)\n","\n","\n","\n","\n","#################################################### main app.py\n","\n","st.title('Welcome - Sentiment Analyzer')\n","st.subheader('Supervised and Unsupervised Learning')\n","\n","menu = ['Home','Login', 'About']\n","choice = st.sidebar.selectbox('Menu', menu)\n","\n","if choice == 'Home':\n","  st.subheader('Welcome to the Sentiment Analyzer Streamlit Application')\n","\n","  sentence = st.text_input('Try the TextBlob sentiment analyzer in a sentence.')\n","  analysis = TextBlob(sentence)\n","  analysis = analysis.sentiment\n","  sent_sentence = polarity(sentence)\n","  sent_sentence = analyze(sent_sentence)\n","  st.write('The polarity and subjectivity of your sentence is', {analysis})\n","  st.write('Here is the sentiment of your sentence:', {sent_sentence})\n","  st.write('\\n')\n","  st.write('NOTE: If the polarity score is > 0 it means your sentence has a positive sentiment. If the polarity score is < 0 it means it has a negative sentiment (Try typing: I hate you). If the polarity score equals 0 its a neutral sentiment.')\n","\n","\n","# We can create a db for the 'Sing up' function, but I don't feel its necessary for now.\n","elif choice == 'Login':\n","  st.subheader('Please login')\n","\n","  username = st.sidebar.text_input(\"User Name\")\n","  password = st.sidebar.text_input(\"Password\",type='password')\n","  if st.sidebar.checkbox(\"Login\"):\n","      if password == 'nlp_analyzer': \n","          st.success('Logged in as {}'.format(username))\n","          task = st.selectbox('Select analysis type', ['Inspect CSV','Clean Text' ,'TextBlob', 'VADER', 'Logistic Regression', 'Support Vector Machine'])\n","          if task == 'Inspect CSV':\n","              st.header('Natural Language Processing')\n","              st.subheader('Inspecting your csv file with sentiment column')\n","\n","              st.write(f'Please upload or drag and drop your csv file.')\n","              #with st.expander('Value Counts and Bar Graph'):\n","              csv_file = st.file_uploader('Upload File - Insepct')\n","\n","              if csv_file:\n","\n","                df = pd.read_csv(csv_file)\n","                x = df['sentiment'].value_counts()\n","                barplot = sns.barplot(x.index,x)\n","                st.write(x)\n","                fig = plt.figure(figsize = (14,5))\n","                sns.barplot(x.index,x)\n","                st.pyplot(fig)\n","\n","          if task == 'Clean Text':\n","              st.header('Natural Language Processing: Text Cleaner')\n","              st.subheader('Preprocessing your Data')\n","              st.write('Please upload or drag and drop your csv file to initiate the preprocessing step.')\n","              st.write('\\n')\n","              st.write('This Text-Cleaner is useful for the TextBlob and VADER Sentiment Analyzers.')\n","              csv_file = st.file_uploader('Upload File - Preprocessing')\n","              if csv_file:\n","                df = pd.read_csv(csv_file)\n","                df[df.Review.str.strip() == ''].shape[0]\n","                norm_corpus = normalize_corpus(df['Review'])\n","                df['Clean Review'] = norm_corpus\n","                df = df[['Review', 'Clean Review']]\n","\n","                df.replace(r'^(\\s?)+$', np.nan, regex=True)\n","                df.dropna().reset_index(drop=True)\n","\n","                df['Clean Review'] = norm_corpus\n","                df = df[['Review', 'Clean Review']]\n","                st.write(df.head())\n","\n","                csv = convert_df(df)\n","                generate_download_button(csv_data=csv, filename='clean', file_label='clean')\n","\n","              \n","              st.write('This Text-Cleaner is useful for the Logistic Regression and Support Vector Machine Analyzers.')\n","              st.write('Why? Unlike the Unsupervised Models we have (TextBlob and VADER), which calculate 3 sentiments, our Unsupervised Models only calculate 2 sentiments -> positive and negative.')\n","              csv_file = st.file_uploader('Upload File - Preprocessing(sentiment column)')\n","              if csv_file:\n","                df = pd.read_csv(csv_file)\n","                df[df.Review.str.strip() == ''].shape[0]\n","                norm_corpus = normalize_corpus(df['Review'])\n","                df['Clean Review'] = norm_corpus\n","                df = df[['Review', 'Clean Review', 'sentiment']]\n","\n","                df.replace(r'^(\\s?)+$', np.nan, regex=True)\n","                df.dropna().reset_index(drop=True)\n","\n","                df['Clean Review'] = norm_corpus\n","                df = df[['Clean Review', 'sentiment']]\n","                st.write(df.head())\n","\n","                csv = convert_df(df)\n","                generate_download_button(csv_data=csv, filename='clean_with_sentiment', file_label='clean_with_sentiment')\n","\n","          if task == 'TextBlob':\n","              st.subheader('TextBlob Lexicon Model')\n","              st.write(f'Please upload or drag and drop your clean preprocess data.')\n","              csv_file = st.file_uploader(\"Upload File (TextBlob Sentiment)\")\n","\n","              if csv_file:\n","                df = pd.read_csv(csv_file)\n","                df['polarity'] = df['Clean Review'].apply(polarity)\n","                df['subjectivity'] = df['Clean Review'].apply(subjectivity)\n","                df['sentiment'] = df['polarity'].apply(analyze)\n","                df = df[['Clean Review', 'polarity', 'subjectivity', 'sentiment']]\n","                st.write(df.head())\n","\n","                csv = convert_df(df)\n","                generate_download_button(csv_data=csv, filename='textblob_analysis', file_label='textblob_analysis')\n","\n","                x = df['sentiment'].value_counts()\n","                barplot = sns.barplot(x.index,x)\n","                st.write(x)\n","                fig = plt.figure(figsize = (14,5))\n","                sns.barplot(x.index,x)\n","                st.pyplot(fig)\n","\n","\n","\n","          if task == 'VADER':\n","              st.subheader('VADER Lexicon Model')\n","              st.write('Please upload or drag and drop your data.')\n","              st.write('VADER does not require preprocess data. It even takes on emojies!')\n","              csv_file = st.file_uploader(\"Upload File\")\n","\n","              if csv_file:\n","                df = pd.read_csv(csv_file)\n","                df['compound'] = df['Review'].apply(vader_sentiment)\n","                df['sentiment'] = df['compound'].apply(vader_analysis)\n","                df = df[['Review', 'compound', 'sentiment']]\n","                st.write(df.head())\n","\n","                csv = convert_df(df)\n","                generate_download_button(csv_data=csv, filename='vader_analysis', file_label='vader_analysis')\n","\n","                x = df['sentiment'].value_counts()\n","                barplot = sns.barplot(x.index,x)\n","                st.write(x)\n","                fig = plt.figure(figsize = (14,5))\n","                sns.barplot(x.index,x)\n","                st.pyplot(fig)\n","\n","\n","\n","          if task == 'Support Vector Machine': \n","              st.subheader('Supervised Learning: Support Vector Machine')\n","              st.write('Please upload or drag and drop your csv file.')\n","              csv_file = st.file_uploader('Upload File - SVM (TF-IDF Model)')\n","              if csv_file:\n","                df = pd.read_csv(csv_file)\n","                df = df[['Clean Review', 'sentiment']].fillna('')\n","                reviews = np.array(df['Clean Review'])\n","                sentiments = np.array(df['sentiment'])\n","\n","                train_reviews = reviews[:35000]\n","                train_sentiments = sentiments[:35000]\n","                test_reviews = reviews[35000:]\n","                test_sentiments = sentiments[35000:]\n","\n","                norm_train_reviews = normalize_corpus(train_reviews)\n","                norm_test_reviews = normalize_corpus(test_reviews)\n","\n","                tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2), sublinear_tf=True)\n","                tv_train_features = tv.fit_transform(norm_train_reviews)\n","\n","                tv_test_features = tv.transform(norm_test_reviews)\n","\n","                st.write('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)\n","\n","                svm = SGDClassifier(loss='hinge', max_iter=100)\n","\n","                svm_tfidf_predictions = train_predict_model(classifier=svm, train_features=tv_train_features, train_labels=train_sentiments, test_features=tv_test_features, test_labels=test_sentiments)\n","\n","                display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_tfidf_predictions, classes=['positive', 'negative'])\n","\n","                classification_rep_tfidf = classification_report(true_labels=test_sentiments, predicted_labels=svm_tfidf_predictions, classes=['positive', 'negative'], output_dict = True)\n","\n","                df_tfidf = pd.DataFrame(classification_rep_tfidf).transpose()\n","                df_tfidf.at['accuracy', 'precision'] = 0.0\n","                df_tfidf.at['accuracy', 'recall'] = 0.0\n","\n","                st.write(df_tfidf)\n","                csv = convert_df(df_tfidf)\n","                generate_download_button(csv_data=csv, filename='svm_tfidf', file_label='svm_tfidf')\n","\n","\n","       \n","              csv_file = st.file_uploader('Upload File - SVM (BOW Model)')\n","              if csv_file:\n","                df = pd.read_csv(csv_file)\n","                df = df[['Clean Review', 'sentiment']].fillna('')\n","                reviews = np.array(df['Clean Review'])\n","                sentiments = np.array(df['sentiment'])\n","\n","                train_reviews = reviews[:35000]\n","                train_sentiments = sentiments[:35000]\n","                test_reviews = reviews[35000:]\n","                test_sentiments = sentiments[35000:]\n","\n","                norm_train_reviews = normalize_corpus(train_reviews)\n","                norm_test_reviews = normalize_corpus(test_reviews)\n","\n","                cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n","\n","                cv_train_features = cv.fit_transform(norm_train_reviews)\n","                cv_test_features = cv.transform(norm_test_reviews)\n","\n","                print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n","\n","                svm = SGDClassifier(loss='hinge', max_iter=100)\n","\n","                svm_bow_predictions = train_predict_model(classifier=svm, train_features=cv_train_features, train_labels=train_sentiments, test_features=cv_test_features, test_labels=test_sentiments)\n","\n","                display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=svm_bow_predictions, classes=['positive', 'negative'])\n","\n","                classification_rep_bow = classification_report(true_labels=test_sentiments, predicted_labels=svm_bow_predictions, classes=['positive', 'negative'], output_dict = True)\n","\n","                df_bow = pd.DataFrame(classification_rep_bow).transpose()\n","                df_bow.at['accuracy', 'precision'] = 0.0\n","                df_bow.at['accuracy', 'recall'] = 0.0\n","\n","                st.write(df_bow)\n","                csv = convert_df(df_bow)\n","                generate_download_button(csv_data=csv, filename='svm_bow', file_label='svm_bow')\n","      \n","\n","          if task == 'Logistic Regression':\n","              st.subheader('Supervised Learning: Logistic Regression')\n","              st.write('Please upload or drag and drop your csv file.')\n","              csv_file = st.file_uploader('Upload File  - Logistic Regression (TF-IDF Model)')\n","              if csv_file:\n","                df = pd.read_csv(csv_file)\n","                df = df[['Clean Review', 'sentiment']].fillna('')\n","                reviews = np.array(df['Clean Review'])\n","                sentiments = np.array(df['sentiment'])\n","\n","                train_reviews = reviews[:35000]\n","                train_sentiments = sentiments[:35000]\n","                test_reviews = reviews[35000:]\n","                test_sentiments = sentiments[35000:]\n","\n","                norm_train_reviews = normalize_corpus(train_reviews)\n","                norm_test_reviews = normalize_corpus(test_reviews)\n","\n","                tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2), sublinear_tf=True)\n","                tv_train_features = tv.fit_transform(norm_train_reviews)\n","\n","                tv_test_features = tv.transform(norm_test_reviews)\n","\n","                st.write('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)\n","\n","                lr = LogisticRegression(penalty='l2', max_iter=500, C=1)\n","\n","                lr_tfidf_predictions = train_predict_model(classifier=lr, train_features=tv_train_features, train_labels=train_sentiments,test_features=tv_test_features, test_labels=test_sentiments)\n","\n","                display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_tfidf_predictions, classes=['positive', 'negative'])\n","\n","                classification_rep_tfidf = classification_report(true_labels=test_sentiments, predicted_labels=lr_tfidf_predictions, classes=['positive', 'negative'], output_dict = True)\n","\n","                df_tfidf = pd.DataFrame(classification_rep_tfidf).transpose()\n","                df_tfidf.at['accuracy', 'precision'] = 0.0\n","                df_tfidf.at['accuracy', 'recall'] = 0.0\n","\n","                st.write(df_tfidf)\n","                csv = convert_df(df_tfidf)\n","                generate_download_button(csv_data=csv, filename='lr_tfidf', file_label='lr_tfidf')\n","\n","\n","\n","\n","              csv_file = st.file_uploader('Upload File - Logistic Regression (BOW Model)')\n","              if csv_file:\n","                df = pd.read_csv(csv_file)\n","                df = df[['Clean Review', 'sentiment']].fillna('')\n","                reviews = np.array(df['Clean Review'])\n","                sentiments = np.array(df['sentiment'])\n","\n","                train_reviews = reviews[:35000]\n","                train_sentiments = sentiments[:35000]\n","                test_reviews = reviews[35000:]\n","                test_sentiments = sentiments[35000:]\n","\n","                norm_train_reviews = normalize_corpus(train_reviews)\n","                norm_test_reviews = normalize_corpus(test_reviews)\n","\n","                cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n","                cv_train_features = cv.fit_transform(norm_train_reviews)\n","\n","                cv_test_features = cv.transform(norm_test_reviews)\n","\n","                st.write('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n","\n","                lr = LogisticRegression(penalty='l2', max_iter=500, C=1)\n","\n","                lr_bow_predictions = train_predict_model(classifier=lr, train_features=cv_train_features, train_labels=train_sentiments,test_features=cv_test_features, test_labels=test_sentiments)\n","\n","                display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_predictions, classes=['positive', 'negative'])\n","\n","                classification_rep_bow = classification_report(true_labels=test_sentiments, predicted_labels=lr_bow_predictions, classes=['positive', 'negative'])\n","\n","                df_bow = pd.DataFrame(classification_rep_bow).transpose()\n","                df_bow.at['accuracy', 'precision'] = 0.0\n","                df_bow.at['accuracy', 'recall'] = 0.0\n","\n","                st.write(df_bow)\n","                csv = convert_df(df_bow)\n","                generate_download_button(csv_data=csv, filename='lr_bow', file_label='lr_bow')\n","\n","      else:\n","          st.warning('Incorrect password. Please email us at nlpfall22@gmail.com in order to recieve a new password.')\n","\n","\n","elif choice == 'About':\n","    st.subheader('About Us')\n"],"metadata":{"id":"9T8mESzHNUuP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666379151253,"user_tz":240,"elapsed":283,"user":{"displayName":"Vicente De Le√≥n W.","userId":"12028395612326007944"}},"outputId":"bc0f6d0d-9a7f-40b2-8b0e-4a826af2dca5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting main_app.py\n"]}]},{"cell_type":"code","source":["!streamlit run /content/main_app.py & npx localtunnel --port 8501"],"metadata":{"id":"3vhaWIaBP3Am"},"execution_count":null,"outputs":[]}]}